{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "006 Messaround with Bernoulli NB models",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RandomForestRanger/PhD/blob/master/006_Messaround_with_Bernoulli_NB_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxZbaaBpuPBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pip installation\n",
        "!pip install --upgrade -q gspread\n",
        "!pip install gspread-dataframe\n",
        "!pip install -U scikit-learn>=0.20\n",
        "!pip install --upgrade scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ2d47wYuSyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "import sklearn.model_selection as ms\n",
        "import sklearn.metrics as sklm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import MultiLabelBinarizer # This one to later turn my LabelsNP into a onehot encoded 2d array\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import BernoulliNB  # this will be operative today...\n",
        "from sklearn.linear_model import LogisticRegression #Mb Added, not sure it should be here... \n",
        "import sklearn.model_selection as ms\n",
        "import sklearn.metrics as sklm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy.random as nr\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlYpC94KATUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#authorise node to access Gdrive via KDL\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXoBAQ8DATY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now containing \"6 short munged and num only 30 Oct IRIS dataset\"\n",
        "\n",
        "#link to pre-opened csv file in my gdrive \n",
        "data1 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1Q2YwmFiFSOkW_V9cRYgZ4GdGGl63_N6mOejEJQB1e0M/edit#gid=835063997')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zCHDcbrATc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the data as a worksheet  \n",
        "ws = data1.worksheet('icanhasdata')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TssdyM_uBPR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert the data to pandas dataframe (can include argument , header = None   if this is needed)\n",
        "FullDF = get_as_dataframe(ws)\n",
        "#inspect data\n",
        "FullDF.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUrvWt62BPho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#since g-sheets brings along a lot of empty/Nan cellumns or rows, this chops them out. Can replace \"all\" with \"any\" if I want to discard any incomplete collumns or rows\n",
        "\n",
        "# I changed the \"all\" to \"any\", to root out all cases of NaN...\n",
        "\n",
        "FullDF.dropna(axis=1, how='all' ,inplace=True )\n",
        "FullDF.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
        "FullDF.tail()\n",
        "\n",
        "# if there are still \"NaN\" values, I want to fill them with \"0\". Go about this thusly:\n",
        "\n",
        "FullDF.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD_HtbuNElhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(FullDF.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZdlBbAmrc5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FeatDF  = FullDF.drop( columns = \"PDV\")\n",
        "LabelDF = FullDF[\"PDV\"]\n",
        "print(FeatDF.shape)\n",
        "print(LabelDF.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXBKmQQ0xm9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convent the DF to a NP array\n",
        "\n",
        "FeatNP  = FeatDF.values\n",
        "LabelNP = LabelDF.values\n",
        "print(\"Feat:\")\n",
        "print(FeatNP.shape)\n",
        "print(FeatNP)\n",
        "print(\"Label:\")\n",
        "print(LabelNP.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NbePQQMx0Qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(FeatNP[0:1,0:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwwzC4q2a6sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Randomly sample cases to create independent training and test data\n",
        "nr.seed(1)\n",
        "indx = range(FeatNP.shape[0])\n",
        "indx = ms.train_test_split(indx, test_size = 100)\n",
        "X_train = FeatNP[indx[0],:]\n",
        "y_train = np.ravel(LabelNP[indx[0]])\n",
        "X_test = FeatNP[indx[1],:]\n",
        "y_test = np.ravel(LabelNP[indx[1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiPh1-iUK86M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"X train shape is: \", X_train.shape, \"\\n\")\n",
        "print(\"X test shape is: \", y_test.shape, \"\\n\")\n",
        "print(\"Y train shape is: \", y_train.shape, \"\\n\")\n",
        "print(\"Y test shape is: \", y_test.shape, \"\\n\")\n",
        "print(\"Unscaled X train record number 700 looks like this: \\n\", X_train[700:701,:])\n",
        "print(np.isnan(X_train.any()))\n",
        "print(np.isfinite(X_train.any()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFx2MVQWa6ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ONLY scale if I'm going to Gaussian...\n",
        "#scale = preprocessing.StandardScaler()\n",
        "#scale.fit(X_train)\n",
        "#X_train = scale.transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN9qyMBK0vsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(\"Scaled X train record number 700 looks like this: \\n\", X_train[700:701,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "f0i9-5X4a6sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4befe6f3-3158-49ae-f654-40db11ebb635"
      },
      "source": [
        "NB_mod = BernoulliNB()\n",
        "\n",
        "##from sklearn.naive_bayes import MultinomialNB\n",
        "##NB_mod = MultinomialNB()\n",
        "##MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "###NB_mod = ComplementNB()\n",
        "\n",
        "NB_mod.fit(X_train, y_train)\n",
        "BernoulliNB(alpha=1.0, class_prior=None, fit_prior=True, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ9mo0SYa6s5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#   X_test = scale.transform(X_test)\n",
        "scores = NB_mod.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg43GlGkvmH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## What, this worked ?!!   ##\n",
        "# MB trying to figure out how to see the coefficients/parameters...\n",
        "print(NB_mod.coef_)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcCGzKEUflsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e61b19eb-3079-485b-cd06-487f805d811e"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['V', 'NP', 'V', 'P', 'NP', 'P', 'D', 'D', 'D', 'V', 'P', 'NP', 'P',\n",
              "       'P', 'P', 'P', 'NP', 'D', 'P', 'NP', 'D', 'P', 'NP', 'NP', 'V',\n",
              "       'P', 'NP', 'D', 'P', 'NP', 'P', 'NP', 'NP', 'NP', 'NP', 'P', 'P',\n",
              "       'P', 'NP', 'NP', 'NP', 'NP', 'V', 'NP', 'NP', 'P', 'P', 'NP', 'NP',\n",
              "       'D', 'P', 'NP', 'NP', 'P', 'NP', 'D', 'NP', 'D', 'NP', 'NP', 'P',\n",
              "       'NP', 'NP', 'P', 'V', 'NP', 'P', 'NP', 'P', 'NP', 'P', 'D', 'P',\n",
              "       'P', 'NP', 'V', 'NP', 'NP', 'D', 'NP', 'D', 'P', 'V', 'NP', 'NP',\n",
              "       'P', 'P', 'P', 'P', 'P', 'NP', 'P', 'NP', 'P', 'NP', 'P', 'NP',\n",
              "       'NP', 'NP', 'D'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaRO30EseUe2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f62a33fd-9eb1-41fc-c2d9-25f9870f3626"
      },
      "source": [
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['D', 'NP', 'P', 'P', 'NP', 'NP', 'D', 'NP', 'P', 'V', 'NP', 'NP',\n",
              "       'NP', 'P', 'P', 'NP', 'NP', 'NP', 'P', 'P', 'V', 'P', 'NP', 'NP',\n",
              "       'P', 'P', 'P', 'NP', 'P', 'NP', 'P', 'P', 'NP', 'NP', 'NP', 'P',\n",
              "       'NP', 'P', 'NP', 'NP', 'NP', 'NP', 'V', 'NP', 'NP', 'P', 'NP',\n",
              "       'NP', 'NP', 'D', 'P', 'NP', 'NP', 'P', 'NP', 'P', 'NP', 'P', 'NP',\n",
              "       'NP', 'D', 'V', 'NP', 'P', 'D', 'NP', 'D', 'P', 'P', 'NP', 'V',\n",
              "       'NP', 'P', 'NP', 'P', 'V', 'NP', 'NP', 'V', 'NP', 'D', 'P', 'V',\n",
              "       'NP', 'D', 'P', 'NP', 'NP', 'P', 'P', 'NP', 'P', 'NP', 'NP', 'V',\n",
              "       'P', 'P', 'NP', 'NP', 'P'], dtype='<U2')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ouXOjAqVa6s_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2c645c6a-fca5-4129-caf9-1c19f48c23fb"
      },
      "source": [
        "def print_metrics_4(labels, scores):\n",
        "   \n",
        "    conf = sklm.confusion_matrix(labels, scores)\n",
        "    print('                 Confusion matrix')\n",
        "    print('                 Score NP         Score P          Score D          Score V')\n",
        "    print('Actual NP      %6d' % conf[0,0] + '            %5d' % conf[0,1] + '             %5d' % conf[0,2]+ '             %5d' % conf[0,3])\n",
        "    print('Actual P       %6d' % conf[1,0] + '            %5d' % conf[1,1] + '             %5d' % conf[1,2]+ '             %5d' % conf[1,3])\n",
        "    print('Actual D       %6d' % conf[2,0] + '            %5d' % conf[2,1] + '             %5d' % conf[2,2]+ '             %5d' % conf[2,3])\n",
        "    print('Actual V       %6d' % conf[3,0] + '            %5d' % conf[3,1] + '             %5d' % conf[3,2]+ '             %5d' % conf[3,3])\n",
        "    ## Now compute and display the accuracy and metrics\n",
        "    print('')\n",
        "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
        "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
        "    print(' ')\n",
        "    print('            NP        P          D          V')\n",
        "    print('Num case    %0.2f' % metrics[3][0] + '     %0.2f' % metrics[3][1] + '      %0.2f' % metrics[3][2]+ '      %0.2f' % metrics[3][3])\n",
        "    print('Precision   %0.2f' % metrics[0][0] + '      %0.2f' % metrics[0][1] + '       %0.2f' % metrics[0][2]+ '       %0.2f' % metrics[0][3])\n",
        "    print('Recall      %0.2f' % metrics[1][0] + '      %0.2f' % metrics[1][1] + '       %0.2f' % metrics[1][2]+ '       %0.2f' % metrics[1][3])\n",
        "    print('F1          %0.2f' % metrics[2][0] + '      %0.2f' % metrics[2][1] + '       %0.2f' % metrics[2][2]+ '       %0.2f' % metrics[2][3])\n",
        "    \n",
        "print_metrics_4(y_test, scores) \n",
        "\n",
        "# with 110 variables, GaussianNB   accuracy is 0.12\n",
        "# with 89 variables,  GaussianNB   accuracy is 0.20 \n",
        "# with 89 variables,  ComplementNB accuracy is 0.33\n",
        "# with 49 variables,  ComplementNB accuracy is 0.55\n",
        "# when i cut out the Unique ID, accuracy moved up to 0.58\n",
        "# Using Bernoulli, I move this up to 0.64 ...(should I cross-validate?)  ...should I run this more than once?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 Confusion matrix\n",
            "                 Score NP         Score P          Score D          Score V\n",
            "Actual NP           3                4                 4                 2\n",
            "Actual P            1               35                 6                 2\n",
            "Actual D            2               10                22                 1\n",
            "Actual V            2                0                 2                 4\n",
            "\n",
            "Accuracy        0.64\n",
            " \n",
            "            NP        P          D          V\n",
            "Num case    13.00     44.00      35.00      8.00\n",
            "Precision   0.38      0.71       0.65       0.44\n",
            "Recall      0.23      0.80       0.63       0.50\n",
            "F1          0.29      0.75       0.64       0.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XMeDelgWabV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf1mNSCHNJpl",
        "colab_type": "text"
      },
      "source": [
        "## Cross validate model\n",
        "\n",
        "To compute a better estimate of model performance, you can perform simple cross validation. The code in the cell performs the following processing:\n",
        "1. Create a list of the metrics to be computed for each fold. \n",
        "2. Defines a logistic regression model object.\n",
        "3. A 10 fold cross validation is performed using the `cross_validate` function from the scikit-learn `model_selection` package.\n",
        "\n",
        "Execute this code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ohzG-x_f9YO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "35e82037-28f0-4964-b2ba-24ed1737f0b8"
      },
      "source": [
        "# First I must binarize my labels\n",
        "MultiLabelBinarizer().fit_transform(LabelNP)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVDjiqcUiNd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RepeatedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY5UJtg-ikjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = ms.RepeatedKFold(n_splits = 5, n_repeats = 10, random_state = 123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jiBAmn5NJps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1646
        },
        "outputId": "57812b46-fd23-4278-fe02-56e7961e506d"
      },
      "source": [
        "#LabelNP = LabelNP.reshape(LabelNP.shape[0],)\n",
        "scoring = ['precision_macro', 'recall_macro', 'roc_auc']\n",
        "#logistic_mod = linear_model.LogisticRegression(C = 1.0, class_weight = {0:0.45, 1:0.55}) \n",
        "scores = ms.cross_validate(NB_mod, FeatNP, LabelNP, scoring=scoring,\n",
        "                        cv=5, return_train_score = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b731a315c0d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#logistic_mod = linear_model.LogisticRegression(C = 1.0, class_weight = {0:0.45, 1:0.55})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m scores = ms.cross_validate(NB_mod, FeatNP, LabelNP, scoring=scoring,\n\u001b[0;32m----> 4\u001b[0;31m                         cv=5, return_train_score = True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_regressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RP6OoA_NJpz",
        "colab_type": "text"
      },
      "source": [
        "The code in the cell below displays the performance metrics along with the mean and standard deviation, computed for each fold to the cross validation. The 'macro' versions of precision and recall are used. These macro versions average over the positive and negative cases. \n",
        "\n",
        "Execute this code, examine the result, and answer **Question 1** on the course page."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "G_cHEh9JNJp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "547487c8-4df5-49c2-f905-9310f4ce43cb"
      },
      "source": [
        "def print_format(f,x,y,z):\n",
        "    print('Fold %2d    %4.3f        %4.3f      %4.3f' % (f, x, y, z))\n",
        "\n",
        "def print_cv(scores):\n",
        "    fold = [x + 1 for x in range(len(scores['test_precision_macro']))]\n",
        "    print('         Precision     Recall       AUC')\n",
        "    [print_format(f,x,y,z) for f,x,y,z in zip(fold, scores['test_precision_macro'], \n",
        "                                          scores['test_recall_macro'],\n",
        "                                          scores['test_roc_auc'])]\n",
        "    print('-' * 40)\n",
        "    print('Mean       %4.3f        %4.3f      %4.3f' % \n",
        "          (np.mean(scores['test_precision_macro']), np.mean(scores['test_recall_macro']), np.mean(scores['test_roc_auc'])))  \n",
        "    print('Std        %4.3f        %4.3f      %4.3f' % \n",
        "          (np.std(scores['test_precision_macro']), np.std(scores['test_recall_macro']), np.std(scores['test_roc_auc'])))\n",
        "\n",
        "print_cv(a)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-e696f0c0d1c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m           (np.std(scores['test_precision_macro']), np.std(scores['test_recall_macro']), np.std(scores['test_roc_auc'])))\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-e696f0c0d1c6>\u001b[0m in \u001b[0;36mprint_cv\u001b[0;34m(scores)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_precision_macro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'         Precision     Recall       AUC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     [print_format(f,x,y,z) for f,x,y,z in zip(fold, scores['test_precision_macro'], \n",
            "\u001b[0;31mTypeError\u001b[0m: 'RepeatedKFold' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYzheviKNJp9",
        "colab_type": "text"
      },
      "source": [
        "Notice that there is considerable variability in each of the performance metrics from fold to fold. Even so, the standard deviations are at least an order of magnitude than the means. It is clear that **any one fold does not provide a representative value of the performance metrics**. The later is a key point as to why cross validation is important when evaluating a machine learning model.  \n",
        "\n",
        "Compare the performance metric values to the values obtained for the baseline model you created above. In general the metrics obtained by cross validation are lower. However, the metrics obtained for the baseline model are within 1 standard deviation of the average metrics from cross validation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMu6Lh0yNJp_",
        "colab_type": "text"
      },
      "source": [
        "## Optimize hyperparameters with nested cross validation\n",
        "\n",
        "Given the variability observed in cross validation, it should be clear that performing model selection from a single training and evaluation is an uncertain proposition at best. Fortunately, the nested cross validation approach provides a better way to perform model selection. However, there is no guarantee that a model selection process will, in fact, improve a model. In some cases, it may prove to be that model selection has minimal impact. \n",
        "\n",
        "To start the nested cross validation process it is necessary to define the randomly sampled folds for the inner and outer loops. The code in the cell below uses the `KFolds` function from the scikit-learn `model_selection` package to define fold selection objects. Notice that the `shuffle = True` argument is used in both cases. This argument specifies that a random shuffle is preformed before folds are created, ensuring that the sampling of the folds for the inside and outside loops are independent. Notice that by creating these independent fold objects there is no need to actually create nested loops for this process. \n",
        "\n",
        "Execute this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlQnVNpKNJqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nr.seed(123)\n",
        "inside = ms.KFold(n_splits=10, shuffle = True)\n",
        "nr.seed(321)\n",
        "outside = ms.KFold(n_splits=10, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjyNJha3NJqL",
        "colab_type": "text"
      },
      "source": [
        "An important decision in model selection searches is the choice of performance metric used to find the best model. For classification problems scikit-learn uses accuracy as the default metric. However, as you have seen previously, accuracy is not necessarily the best metric, particularly when there is a class imbalance as is the case here. There are a number of alternatives which one could choose for such a situation. In this case AUC will be used. \n",
        "\n",
        "The code below uses the `inside` k-fold object to execute the inside loop of the nested cross validation. Specifically, the steps are:\n",
        "1. Define a dictionary with the grid of parameter values to search over. In this case there is only one parameter, `C`, with a list of values to try. In a more general case, the dictionary can contain values from multiple parameters, creating a multi-dimensional grid that the cross validation process will iterate over. In this case there are 5 hyperparameter values in the grid and 10-fold cross validation is being used. Thus, the model will be trained and evaluated 50 times. \n",
        "2. The logistic regression model object is defined. \n",
        "3. The cross validation search over the parameter grid is performed using the `GridSearch` function from the scikit-learn `model_selection` package. Notice that the cross validation folds are computed using the `inside` k-fold object.\n",
        "\n",
        "\n",
        "****\n",
        "**Note:** Somewhat confusingly, the scikit-learn `LogisticRegression` function uses a regularization parameter `C` which is the inverse of the usual l2 regularization parameter $\\lambda$. Thus, the smaller the parameter the stronger the regulation \n",
        "****\n",
        "\n",
        "Execute this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Pjm1Rx0QNJqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nr.seed(3456)\n",
        "## Define the dictionary for the grid search and the model object to search on\n",
        "param_grid = {\"C\": [0.1, 1, 10, 100, 1000]}\n",
        "## Define the logistic regression model\n",
        "logistic_mod = linear_model.LogisticRegression(class_weight = {0:0.45, 0:0.55}) \n",
        "\n",
        "## Perform the grid search over the parameters\n",
        "clf = ms.GridSearchCV(estimator = logistic_mod, param_grid = param_grid, \n",
        "                      cv = inside, # Use the inside folds\n",
        "                      scoring = 'roc_auc',\n",
        "                      return_train_score = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvgxDQZTNJqT",
        "colab_type": "text"
      },
      "source": [
        "The cross validated grid search object, `clf`, has been created. \n",
        "\n",
        "The code in the cell below fits the cross validated model using the `fit`method. The AUC for each hyperparameter and fold is displayed as an array. Finally, the hyperparameter for the model with the best average AUC is displayed.  Execute this code and  examine the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMO83zZPNJqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Fit thhe cross validated grid search over the data \n",
        "clf.fit(Features, Labels)\n",
        "keys = list(clf.cv_results_.keys())\n",
        "for key in keys[6:16]:\n",
        "    print(clf.cv_results_[key])\n",
        "## And print the best parameter value\n",
        "clf.best_estimator_.C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHSbWsElNJqa",
        "colab_type": "text"
      },
      "source": [
        "The array of AUC metrics has dimensions 10 folds X  hyperparameter values. As you might expect by now, there is considerable variation in the AUC from fold to fold for each hyperparamter value, or column. \n",
        "\n",
        "Evidently, the optimal hyperparameter value is 0.1. \n",
        "\n",
        "To help understand this behavior a bit more, the code in the cell below does the following:\n",
        "1. Compute and display the mean and standard deviation of the AUC for each hyperparameter value.\n",
        "2. Plot the AUC values for each fold vs. the hyperparameter values. The mean AUC for each hyperparameter value is shown with a red +. \n",
        "\n",
        "Execute this code and examine the results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJKhgsyYNJqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_cv(clf, params_grid, param = 'C'):\n",
        "    params = [x for x in params_grid[param]]\n",
        "  \n",
        "    keys = list(clf.cv_results_.keys())              \n",
        "    grid = np.array([clf.cv_results_[key] for key in keys[6:16]])\n",
        "    means = np.mean(grid, axis = 0)\n",
        "    stds = np.std(grid, axis = 0)\n",
        "    print('Performance metrics by parameter')\n",
        "    print('Parameter   Mean performance   STD performance')\n",
        "    for x,y,z in zip(params, means, stds):\n",
        "        print('%8.2f        %6.5f            %6.5f' % (x,y,z))\n",
        "    \n",
        "    params = [math.log10(x) for x in params]\n",
        "    \n",
        "    plt.scatter(params * grid.shape[0], grid.flatten())\n",
        "    p = plt.scatter(params, means, color = 'red', marker = '+', s = 300)\n",
        "    plt.plot(params, np.transpose(grid))\n",
        "    plt.title('Performance metric vs. log parameter value\\n from cross validation')\n",
        "    plt.xlabel('Log hyperparameter value')\n",
        "    plt.ylabel('Performance metric')\n",
        "    \n",
        "plot_cv(clf, param_grid)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOGkMuiWNJqg",
        "colab_type": "text"
      },
      "source": [
        "There are a number of points to notice here:\n",
        "1. The mean AUC for each value of the hyperparameter are all within 1 standard deviation of each other. This result indicates that model performance is not sensitive to the choice of hyperparamter. \n",
        "2. Graphically you can see that there is a noticeable variation in the AUC from metric to metric, regardless of hyperparameter. Keep in mind that **this variation is simply a result of random sampling of the data!**\n",
        "\n",
        "Finally, it is time to try execute the outer loop of the nested cross validation to evaluate the performance of the 'best' model selected by the inner loop. In this case, 'best' is quite approximate, since as already noted, the differences in performance between the models is not significant. \n",
        "\n",
        "The code in the cell below executes the outer loop of the nested cross validation using the `cross_val_scores` function from the scikit-learn `model_selection` package. The folds are determined by the `outside` k-fold object. The mean and standard deviation of the AUC is printed along with the value estimated for each fold. Execute this code and examine the result. \n",
        "\n",
        "Then, answer **Question 2** on the course page."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlYXSXMdNJqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nr.seed(498)\n",
        "cv_estimate = ms.cross_val_score(clf, Features, Labels, \n",
        "                                 cv = outside) # Use the outside folds\n",
        "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
        "\n",
        "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
        "print('Outcomes by cv fold')\n",
        "for i, x in enumerate(cv_estimate):\n",
        "    print('Fold %2d    %4.3f' % (i+1, x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBkIje6cNJqr",
        "colab_type": "text"
      },
      "source": [
        "As expected, there is considerable variation in AUC across the folds. The mean AUC is a bit lower than estimated for the inner loop of the nested cross validation and the baseline model. However, all of these values are within 1 standard deviation of each other, and thus these differences cannot be considered significant. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg9kec1rNJqv",
        "colab_type": "text"
      },
      "source": [
        "Now, you will build and test a model using the estimated optimal hyperparameters. Then, answer **Question 3** on the course page. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T3-stXeNJqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logistic_mod = linear_model.LogisticRegression(C = 0.1, class_weight = {0:0.45, 1:0.55}) \n",
        "logistic_mod.fit(X_train, y_train)\n",
        "probabilities = logistic_mod.predict_proba(X_test)\n",
        "print_metrics(y_test, probabilities, 0.3)  \n",
        "plot_auc(y_test, probabilities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obxp3a5mNJq1",
        "colab_type": "text"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this lab you have performed by simple cross validation and nested cross validation. Key points and observations are:\n",
        "1. Model selection should be done using a resampling procedure such as nested cross validation. The nested sampling structure is required to prevent bias in model selection wherein the model selected learns the best hyperparameters for the samples used, rather than a model that generalizes well. \n",
        "2. There is significant variation in model performance from fold to fold in cross validation. This variation arises from the sampling of the data alone and is not a property of any particular model.\n",
        "3. Given the expected sampling variation in cross validation, there is generally considerable uncertainty as to which model is best when performing model selection.  "
      ]
    }
  ]
}